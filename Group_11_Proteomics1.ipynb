{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Csdq2BtJJAbm",
    "outputId": "f282a067-6de9-4fbc-a447-b1018806fbad"
   },
   "source": "!pip install dash_bio pandas plotly scipy scikit-learn pyteomics biopython pyteomics",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oq8V0ZTlJqsc"
   },
   "source": [
    "# Exercise on Proteomics Data Handling and Peptide Identification\n",
    "\n",
    "In this exercise we want to get used to the data of proteomics including protein sequences and spectrum data. We also want to answer the following questions:\n",
    "\n",
    "1. How many reviewed canonical protein sequences for human are in UniProt?\n",
    "2. How many reviewed canonical and isoform protein sequences for human are in UniProt?\n",
    "3. Using a Trypsin digest, how many peptides with length between 7 and 35 amino acids are in the reviewed canonical and isoform database for human?\n",
    "4. How are the masses of these peptides distributed?\n",
    "5. In the example MGF spectrum data, how many precursors are there that match the mass of the peptide sequence PEPTIDE with an error tolerance of 10ppm?\n",
    "\n",
    "For this, we will implement an easy computational workflow for peptide identification using a database search strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dvzuCwF9La6b"
   },
   "source": [
    "# The Data\n",
    "\n",
    "There are several files that are required for the exercise.\n",
    "# FASTA\n",
    "The FASTA database of both the canonical and the canonical+isoform protein sequences can be downloaded from [uniprot.org](https://uniprot.org). Clock on 'Reviewed (Swiss-Prot)' in the blue panel 'Proteins, UniProt Knowledgebases', then select 'Human' on the left side. Download the databases using the 'Download' section above the table. Select 'FASTA (canonical)' or 'FASTA (canonical & isoform)', change the compression selection to 'No' and proceed to download.\n",
    "Both FASTA databases are also available on a USB flash drive - ask during the hands-on sections.\n",
    "\n",
    "# Spectrum Data (MGF)\n",
    "The spectrum data is available in the moodle course. For the in-class exercise please use the 'in-class_exercise.mgf' file and continue at home with the 'home-exercise.mgf' file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6rworUVrNLP8"
   },
   "source": [
    "**Task 1: FASTA loading and counting entries**\n",
    "- Read in the one of the fasta files and store all proteins therein in a suitable datastructure.\n",
    "- Extract the Protein ID from the header (e.g. P10636 from >sp|P10636|MAPT_HUMAN...)\n",
    "- Count entries in FASTA"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 433
    },
    "id": "qnKZ4Ec4CVcq",
    "outputId": "69fe3996-86c1-483c-b372-6ca6727d1045"
   },
   "source": [
    "from pyteomics import fasta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "fasta_df = pd.DataFrame(columns=['protein_id', 'sequence'])\n",
    "fasta_df_slices = []\n",
    "for header, sequence in fasta.read(\"data/uniprotkb_human_proteins_isoforms.fasta\"):\n",
    "    fasta_df_slices.append(pd.DataFrame({'protein_id': [header.split('|')[1]], 'sequence': [sequence]}))\n",
    "\n",
    "fasta_df = pd.concat(fasta_df_slices)\n",
    "fasta_df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B5OIZXegp9yB"
   },
   "source": [
    "**Task 2: Decoy generation and digestion**\n",
    "TODO update the description of this task\n",
    "- Digest proteins into peptides using the Tryptic cleavage rule '[KR]!P'\n",
    "- Filter only peptides with length between 7 and 35 amino acids\n",
    "- Count the number of unique peptide sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AGJew1iVqhWA"
   },
   "source": [
    "**Task 3: Peptide masses**\n",
    "- Calculate the peptide masses for all peptides\n",
    "- CAVE: There might be amino acid single letter codes included that do not have an associated mass (e.g. U, X). Make sure you exclude these from the calculation first\n",
    "- Plot the mass distribution"
   ]
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "collapsed": true,
    "id": "GliQ_XQVgX_6",
    "outputId": "b864b176-65b5-4066-dfdc-0cd6ead7f058"
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "from pyteomics import mass\n",
    "from decoy_database import generate_decoy_peptides\n",
    "def check(str, pattern):\n",
    "    if re.search(pattern, str):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "PEPTIDE_DF_PATH = \"data/peptide_df.csv\"\n",
    "try:\n",
    "    peptide_df = pd.read_csv(PEPTIDE_DF_PATH, index_col=0)\n",
    "except FileNotFoundError:\n",
    "    results = generate_decoy_peptides(fasta_df)\n",
    "    target_peptide_df = results['target_peptides']\n",
    "    decoy_peptide_df = results['decoy_peptides']\n",
    "    peptide_df = pd.concat([target_peptide_df, decoy_peptide_df])\n",
    "    pattern = re.compile('^[ACDEFGHIKLMNPQRSTVWYp]+$')\n",
    "    peptide_df['peptide_mass'] = -1\n",
    "    peptide_df['fragments'] = None\n",
    "    peptide_df = peptide_df[peptide_df['sequence'].apply(lambda x: check(x, pattern))]\n",
    "    peptide_df['peptide_mass'] = peptide_df['sequence'].apply(lambda x: mass.calculate_mass(x))\n",
    "    peptide_df.sort_values(by=['peptide_mass'], ascending=True, inplace=True)\n",
    "    #peptide_df.drop_duplicates(subset=[\"sequence\"], inplace=True)\n",
    "    peptide_df.to_csv(PEPTIDE_DF_PATH)\n",
    "\n",
    "peptide_df\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k5jf2z_m6Amo"
   },
   "source": [
    "**Task 5: Calculate fragment ions of candidate peptides**\n",
    "- calculate all b- and y-fragment ions for a given candidate peptide\n",
    "- include all fragment ions with a charge up to the precursor charge"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "i9UnwP0U6TRn"
   },
   "source": [
    "from pyteomics import mass, parser\n",
    "import numpy as np\n",
    "import re\n",
    "from functools import lru_cache\n",
    "from math import comb\n",
    "\n",
    "aa_comp = dict(mass.std_aa_comp)\n",
    "\n",
    "def fragments(peptide, types=('b', 'y'), maxcharge=1):\n",
    "    \"\"\"\n",
    "    The function generates all possible m/z for fragments of types\n",
    "    `types` and of charges from 1 to `maxcharge`.\n",
    "    \"\"\"\n",
    "    parsed_parts = parser.parse(peptide)\n",
    "    for i in range(1, len(parsed_parts)):\n",
    "        for ion_type in types:\n",
    "            for charge in range(1, maxcharge+1):\n",
    "                if ion_type[0] in 'abc':\n",
    "                    yield mass.calculate_mass(\n",
    "                            \"\".join(parsed_parts[:i]), ion_type=ion_type, charge=charge, aa_comp=aa_comp)\n",
    "                else:\n",
    "                    yield mass.calculate_mass(\n",
    "                             \"\".join(parsed_parts[i:]), ion_type=ion_type, charge=charge, aa_comp=aa_comp)\n",
    "\n",
    "def calculate_peptide_mass(peptide_mz: float, charge: int) -> float:\n",
    "    proton_mass = 1.007276466812\n",
    "    return (peptide_mz * charge) - (proton_mass * charge)\n",
    "\n",
    "def get_scan_id(text : str) -> int:\n",
    "  matches = re.findall(r'scan=\\d+', text)\n",
    "  return matches[0].split('=')[1]\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "1iWqznO02fcw",
    "outputId": "7c7e6604-0f8d-4091-ca94-bb98cea026dc"
   },
   "source": [
    "from pyteomics import mgf\n",
    "from tqdm import tqdm\n",
    "mgf_df = pd.DataFrame(columns=['experiment_name', 'precursor_mass', 'precursor_mz', 'mz_array', 'intensity_array, scan_id'])\n",
    "mgf_df_slices = []\n",
    "\n",
    "file_list = [\"data/new_CTR03_BA46_INSOLUBLE_01.mgf\", \"data/new_CTR08_BA46_INSOLUBLE_01.mgf\", \"data/new_CTR45_BA46_INSOLUBLE_01.mgf\"]\n",
    "#file_list = [\"data/home_exercise.mgf\"]\n",
    "for file in file_list:\n",
    "    with mgf.read(file) as reader:\n",
    "        for spectrum in tqdm(reader):\n",
    "          if spectrum is None or spectrum['params'] is None:\n",
    "            continue\n",
    "          params = spectrum['params']\n",
    "          scan = get_scan_id(params['title'])\n",
    "          mz_array = spectrum['m/z array']\n",
    "          intensity_array = spectrum['intensity array']\n",
    "          charge = int(params['charge'][0])\n",
    "          precursor_mz = params['pepmass'][0]\n",
    "          peptide_mass = calculate_peptide_mass(precursor_mz, charge)\n",
    "          mgf_df_slices.append(pd.DataFrame({'experiment_name': file.split(\"/\")[-1].split(\".\")[0], 'precursor_mass': [peptide_mass], 'precursor_mz' : [precursor_mz], 'mz_array': [mz_array], 'intensity_array': [intensity_array], \"scan_id\": scan}))\n",
    "mgf_df = pd.concat(mgf_df_slices)\n",
    "mgf_df\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kabCcdqf3Cxm"
   },
   "source": [
    "from scoring_function import optimize_q_wrapper\n",
    "from simple_scoring_function import simple_scoring_function\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from pyteomics import mass\n",
    "from scoring_function import optimize_q_wrapper\n",
    "MATCHED_SPECTRA_DF_PATH = \"data/matched_spectra_df.csv\"\n",
    "try:\n",
    "    matched_spectra_df = pd.read_csv(MATCHED_SPECTRA_DF_PATH)\n",
    "except FileNotFoundError:\n",
    "    skips = 50\n",
    "    matched_spectra_df = pd.DataFrame(columns=['experiment_name', 'protein_id', 'precursor_mass', 'precursor_mz', 'mz_array', 'intensity_array', 'sequence', 'peptide_mass', 'fragments', 'match_score', \"scan_id\", \"scoring_function\"])\n",
    "    matched_spectra_df_slices = []\n",
    "    for scoring_function in [optimize_q_wrapper, simple_scoring_function]:\n",
    "        for idx, spectrum in tqdm(mgf_df.iloc[::skips].iterrows(),\n",
    "                                  desc=f\"Scoring using {scoring_function.__name__}\",\n",
    "                                  total=len(mgf_df)/skips):\n",
    "          # find candidates with ppm of 10\n",
    "          precursor_mass = spectrum['precursor_mass']\n",
    "          tolerance = 10 / 1_000_000  # Define the tolerance as a fraction\n",
    "          candidates = peptide_df[\n",
    "            (precursor_mass >= peptide_df['peptide_mass'] * (1 - tolerance)) &\n",
    "            (precursor_mass <= peptide_df['peptide_mass'] * (1 + tolerance))\n",
    "          ]\n",
    "          if len(candidates) == 0:\n",
    "            continue\n",
    "\n",
    "          best_match = (-1, \"\")\n",
    "          for __, candidate in candidates.iterrows():\n",
    "            sequence = candidate['sequence']\n",
    "            theoretical_spectrum = np.array(list(fragments(sequence)))\n",
    "            experimental_mz_array = spectrum['mz_array']\n",
    "            experimental_intensity_array = spectrum['intensity_array']\n",
    "            experimental_spectrum = pd.DataFrame({'mz': experimental_mz_array, 'intensity': experimental_intensity_array}).to_numpy()\n",
    "            if len(theoretical_spectrum) == 0:\n",
    "              print(theoretical_spectrum)\n",
    "              print(f\"Could not fragment peptide {sequence}\")\n",
    "              continue\n",
    "            score = scoring_function(theoretical_spectrum, experimental_spectrum, 20)\n",
    "            if score > best_match[0]:\n",
    "              best_match = (score, sequence, candidate['protein_id'])\n",
    "\n",
    "          match_score, sequence, source_protein_id = best_match\n",
    "          bm = candidates[candidates['sequence'] == sequence]\n",
    "          peptide_mass = bm['peptide_mass'].values[0]\n",
    "          matched_spectra_df_slices.append(\n",
    "                 pd.DataFrame({'experiment_name': spectrum['experiment_name'],\n",
    "                                'protein_id': source_protein_id,\n",
    "                                'precursor_mass': [spectrum['precursor_mass']],\n",
    "                                'precursor_mz' : [spectrum['precursor_mz']],\n",
    "                                'mz_array': [spectrum['mz_array']],\n",
    "                                'intensity_array': [spectrum['intensity_array']],\n",
    "                                'sequence': [sequence],\n",
    "                                'peptide_mass': [peptide_mass],\n",
    "                                'fragments': [theoretical_spectrum],\n",
    "                                'match_score': [match_score],\n",
    "                                'scan_id': spectrum['scan_id'],\n",
    "                                'scoring_function': scoring_function.__name__\n",
    "                               },\n",
    "            )\n",
    "          )\n",
    "    matched_spectra_df = pd.concat(matched_spectra_df_slices)\n",
    "    # sort the np array stored in intensity_array, mz_array and fragments with apply\n",
    "    matched_spectra_df['intensity_array'] = matched_spectra_df['intensity_array'].apply(lambda x: np.array(x))\n",
    "    matched_spectra_df['mz_array'] = matched_spectra_df['mz_array'].apply(lambda x: np.array(x))\n",
    "    matched_spectra_df['fragments'] = matched_spectra_df['fragments'].apply(lambda x: np.array(x))\n",
    "    matched_spectra_df.sort_values(by=['match_score'], ascending=False, inplace=True)\n",
    "    matched_spectra_df.to_csv(MATCHED_SPECTRA_DF_PATH)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "matched_spectra_df",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming df is already loaded as matched_spectra_df\n",
    "df = matched_spectra_df.copy()\n",
    "\n",
    "# 1. Create log2 transformed match scores (handle zero/negative values if they exist)\n",
    "df['log2_match_score'] = np.log2(df['match_score'])\n",
    "\n",
    "# Clean infinite values from log transformation\n",
    "df = df.replace([-np.inf, np.inf], np.nan).dropna(subset=['log2_match_score'])\n",
    "\n",
    "# 2. Create the facet grid\n",
    "g = sns.FacetGrid(\n",
    "    df,\n",
    "    col='experiment_name',\n",
    "    row='scoring_function',\n",
    "    hue='side',\n",
    "    palette={'Decoys': 'blue', 'Non-decoys': 'red'},\n",
    "    height=4,\n",
    "    aspect=1.5,\n",
    "    sharex=True,\n",
    "    sharey=True\n",
    ")\n",
    "\n",
    "# 3. Map KDE plots to the grid\n",
    "g.map(sns.kdeplot, 'log2_match_score', fill=True, alpha=0.5, linewidth=1.5)\n",
    "\n",
    "# 4. Customize plot appearance\n",
    "g.set_axis_labels('log2(Match Score)', 'Density')\n",
    "g.set_titles(col_template='Experiment: {col_name}', row_template='Scoring: {row_name}')\n",
    "g.add_legend(title='Category')\n",
    "\n",
    "# Adjust layout and show\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "df = matched_spectra_df\n",
    "\n",
    "# Load your DataFrame here (replace this with your actual data)\n",
    "# df = pd.read_csv(...)\n",
    "\n",
    "# Check if 'protein_id' exists and has no NaN values\n",
    "if 'protein_id' not in df.columns or df['protein_id'].isnull().all():\n",
    "    raise ValueError(\"Column 'protein_id' is missing or contains no valid data.\")\n",
    "\n",
    "# Identify decoys and non-decoys\n",
    "df['side'] = df['protein_id'].str.contains('XXX_', na=False).map({\n",
    "    True: 'Decoys',\n",
    "    False: 'Non-decoys'\n",
    "})\n",
    "\n",
    "# Check if both categories exist\n",
    "side_counts = df['side'].value_counts()\n",
    "if 'Decoys' not in side_counts or 'Non-decoys' not in side_counts:\n",
    "    print(\"Warning: One of the categories (Decoys/Non-decoys) is missing. Adjusting plot...\")\n",
    "\n",
    "# Ensure 'experiment_name' and 'scoring_function' have valid data\n",
    "required_columns = ['experiment_name', 'scoring_function', 'match_score']\n",
    "for col in required_columns:\n",
    "    if col not in df.columns:\n",
    "        raise ValueError(f\"Required column '{col}' is missing.\")\n",
    "\n",
    "# Generate the violin plot\n",
    "try:\n",
    "    fig = px.violin(\n",
    "        df,\n",
    "        x='scoring_function',\n",
    "        y='match_score',\n",
    "        color='side',\n",
    "        facet_col='experiment_name',\n",
    "        box=True,\n",
    "        points=\"outliers\",\n",
    "        title='Match Score Distribution: Decoys (Left) vs. Non-decoys (Right)',\n",
    "        category_orders={\n",
    "            'side': ['Decoys', 'Non-decoys'],  # Explicit order for left/right placement\n",
    "            'scoring_function': sorted(df['scoring_function'].unique()),  # Ensure consistent order\n",
    "            'experiment_name': sorted(df['experiment_name'].unique())\n",
    "        },\n",
    "        labels={'match_score': 'Match Score', 'scoring_function': 'Scoring Function'},\n",
    "        log_y=True\n",
    "    )\n",
    "\n",
    "    # Adjust layout to group violins\n",
    "    fig.update_layout(\n",
    "        violinmode='group',\n",
    "        violingap=0,\n",
    "        violingroupgap=0\n",
    "    )\n",
    "\n",
    "    # Show the plot\n",
    "    fig.show()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Plotting failed: {e}\")\n",
    "    # Optionally, display partial data for debugging\n",
    "    print(\"\\nSample of DataFrame used for plotting:\")\n",
    "    print(df[['experiment_name', 'scoring_function', 'side', 'match_score']].head())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming df is already loaded as matched_spectra_df\n",
    "df = matched_spectra_df.copy()\n",
    "\n",
    "# 1. Create 'side' column first!\n",
    "df['side'] = df['protein_id'].str.contains('XXX_', na=False).map({\n",
    "    True: 'Decoys',\n",
    "    False: 'Non-decoys'\n",
    "})\n",
    "\n",
    "# 2. Convert match_score to numeric\n",
    "df['match_score'] = pd.to_numeric(df['match_score'], errors='coerce')\n",
    "df = df.dropna(subset=['match_score'])\n",
    "df = df[df['match_score'] > 0]  # Remove zero/negative values\n",
    "\n",
    "# 3. Apply log2 transformation with protection\n",
    "df['log2_match_score'] = np.log2(df['match_score'].clip(lower=1e-9))\n",
    "\n",
    "# 4. Verify 'side' exists\n",
    "if 'side' not in df.columns:\n",
    "    raise KeyError(\"'side' column creation failed - check protein_id values\")\n",
    "\n",
    "# 5. Create facet grid with color mapping\n",
    "g = sns.FacetGrid(\n",
    "    df,\n",
    "    col='experiment_name',\n",
    "    row='scoring_function',\n",
    "    hue='side',\n",
    "    palette={'Decoys': 'blue', 'Non-decoys': 'red'},\n",
    "    height=4,\n",
    "    aspect=1.5,\n",
    "    sharex=True,\n",
    "    sharey=True\n",
    ")\n",
    "\n",
    "# 6. Add KDE plots\n",
    "g.map(sns.kdeplot, 'log2_match_score', fill=True, alpha=0.5, linewidth=1.5)\n",
    "\n",
    "# 7. Customize labels and titles\n",
    "g.set_axis_labels('log2(Match Score)', 'Density')\n",
    "g.set_titles(col_template='Experiment: {col_name}', row_template='Scoring: {row_name}')\n",
    "g.add_legend(title='Category')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kvCg3E-gTSYN"
   },
   "source": [
    "from matplotlib import pyplot as plt\n",
    "matched_spectra_df.plot(kind='scatter', x='peptide_mass', y='match_score', s=32, alpha=.8)\n",
    "plt.gca().spines[['top', 'right',]].set_visible(False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "yrDzNMEFTLNq"
   },
   "source": [
    "from matplotlib import pyplot as plt\n",
    "matched_spectra_df['match_score'].plot(kind='hist', bins=20, title='match_score')\n",
    "plt.gca().spines[['top', 'right',]].set_visible(False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "CghFTD2tGxtB"
   },
   "source": [
    "matched_spectra_df.sort_values(by=['match_score'], ascending=False, inplace=True)\n",
    "confidently_matched_spectra_df = matched_spectra_df[matched_spectra_df['match_score'] > 0.5]\n",
    "print(f\"{len(confidently_matched_spectra_df)} spectra could be identified with a score above 0.5 (50% of theoretical peaks matched).\")\n",
    "confidently_matched_spectra_df"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
